{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook has following goals:\n",
    "\n",
    "- Get difference between old and new wiki page\n",
    "- Cleaning (lower cases, removing stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Pieter-Jan\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data manipulation\n",
    "\n",
    "from difflib import unified_diff\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit, regexp_replace, lower\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import types\n",
    "\n",
    "# other\n",
    "from threading import Thread\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables (use capital letter for variables)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "current_palette = sns.color_palette(\"colorblind\")\n",
    "# sns.palplot(current_palette)\n",
    "sns.set_palette(\"colorblind\")\n",
    "DPI = 500 # determines quality when saving figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get streaming instances\n",
    "This section is only for the purpose to set up and do intermediate checks of the pipeline with live data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only serves as trial to test my functions on live incoming instances\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    # Start stream\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    # Stop stream\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
    "\n",
    "# ssc = StreamingContext(sc, 10) # Every 10 seconds, construct a mini-batch of RDDs\n",
    "# lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "# lines.pprint()\n",
    "# ssc_t = StreamingThread(ssc)\n",
    "# ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc_t.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Spark dataframe --> various sites state that a dataframe is better than a DDR for textual data\n",
    "\n",
    "def get_wiki_df(path = \"../../data/*\"):\n",
    "    \n",
    "    \"\"\" reads in the data\n",
    "    Args\n",
    "        path (str): the path can be either a single text file or a directory storing text files. \n",
    "    Returns\n",
    "        (pyspark.sql.dataframe.DataFrame) textual data\n",
    "    \"\"\"\n",
    "\n",
    "    wiki_df = spark.read.json(path)\n",
    "\n",
    "    # Uncomment if you want its schema\n",
    "    # wiki_df.printSchema()\n",
    "    return wiki_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_count(wiki_df):\n",
    "    \n",
    "    \"\"\" For this function you should only pass the full \n",
    "    wiki_df in order to get the label count.\n",
    "    --------------------------------------\n",
    "    Last result (so you don't need to run it each time) \n",
    "    -> safe: 30333, unsafe: 4136, vandal: 270\n",
    "    \"\"\"\n",
    "    # Creates a temporary view using the wiki DataFrame\n",
    "    wiki_df.createOrReplaceTempView(\"wikidata\")                            \n",
    "                                                                                  \n",
    "    # Check the amount of safes/unsafes/vandals                                    \n",
    "    label_df = spark.sql(\"SELECT label, count(*) FROM wikidata GROUP BY label\")    \n",
    "    return label_df  \n",
    "\n",
    "\n",
    "def show_X_rows(df, x): \n",
    "    \n",
    "    \"\"\"  Shows first X number of spark dataframe rows\n",
    "    Input the dataframe followed by a \n",
    "    number in order to see the first x amount\n",
    "    of rows\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert list to RDD\n",
    "    rdd = spark.sparkContext.parallelize(df.take(x))\n",
    "\n",
    "    # Create data frame\n",
    "    df_temp = spark.createDataFrame(rdd)\n",
    "    return df_temp.show()\n",
    "\n",
    "def flatten(nested_list):\n",
    "    \n",
    "    \"\"\" Function that flattens a nested list.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    flat_list = []\n",
    "    for sublist in nested_list:\n",
    "        if type(sublist) == list:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(sublist)\n",
    "            \n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Function to get the difference between old and new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edited part of wiki page (credits to the professor)\n",
    "def get_diff_1(old, new):\n",
    "    \n",
    "    \"\"\"\" Takes in old and new columns and \n",
    "    returns the difference between the two\n",
    "    \"\"\"\n",
    "    \n",
    "    return '\\n'.join([ l for l in unified_diff(old.split('\\n'), new.split('\\n')) if l.startswith('+') or l.startswith('-') ])\n",
    "\n",
    "# The difference function that will take a very long time to compute for all instances\n",
    "def get_diff_2(old, new):\n",
    "    \n",
    "    \"\"\" Takes in old and new columns and \n",
    "    returns the difference between the two\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    deleted_words = []\n",
    "    added_words = []\n",
    "    temp_i = -100\n",
    "    new_word = ''\n",
    "    status = 'none'\n",
    "    for i, s in enumerate(difflib.ndiff(old, new)):\n",
    "        if s[0] == ' ':\n",
    "            if status == 'adding':\n",
    "                added_words.append(new_word)\n",
    "                new_word = ''\n",
    "            elif status == 'deleting':\n",
    "                deleted_words.append(new_word)\n",
    "                new_word = ''\n",
    "            status = 'none'\n",
    "            continue\n",
    "        elif s[0] == '-':\n",
    "            if status != 'deleting':\n",
    "                added_words.append(new_word)\n",
    "                new_word = ''\n",
    "                status = 'deleting'\n",
    "            new_word += s[-1]\n",
    "        elif s[0] == '+':\n",
    "            if status != 'adding':\n",
    "                deleted_words.append(new_word)\n",
    "                new_word = ''\n",
    "                status = 'adding'\n",
    "            new_word += s[-1]\n",
    "    if new_word != '' and status == 'deleting':\n",
    "        deleted_words.append(new_word)\n",
    "    elif new_word != '' and status == 'adding':\n",
    "        added_words.append(new_word)\n",
    "    return {'added': added_words, 'deleted': deleted_words}\n",
    "\n",
    "def get_deletions(del_add):\n",
    "    \n",
    "    \"\"\" returns the deleted\n",
    "    words out of a list of deleted and added\n",
    "    words\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    return del_add['deleted']\n",
    "\n",
    "def get_additions(del_add):\n",
    "    \n",
    "    \"\"\"\" returns the added\n",
    "    words out of a list of deleted and added\n",
    "    words\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return del_add['added']\n",
    "\n",
    "def extract_differences(str_old, str_new):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that splits old and new string\n",
    "    and extracts its differences\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Clean old and new wiki pages from html characters\n",
    "        str_old, str_new = cleanhtml(str_old), cleanhtml(str_new)\n",
    "\n",
    "        # Get big chunks of altered fragments\n",
    "        diff1 = get_diff_1(str_old, str_new)\n",
    "\n",
    "\n",
    "        # Clean the differences from unwanted characters to get only words\n",
    "        diff2 = []\n",
    "        for txt in diff1.split('\\n'):\n",
    "            diff2.append(''.join([x for x in txt if x in string.ascii_letters + '\\'-+ 1234567890']).lower())\n",
    "\n",
    "        # Find chunks that are related ('+' vs '-') else append them to a seperate list that doesn't need to get processed in the next part\n",
    "        fully_added, fully_removed, partly_new, partly_old = find_similar_chunks(diff2)\n",
    "\n",
    "        # Get the individual fragments that were added or deleted\n",
    "        for i in range(0,len(partly_new)):\n",
    "            difference = get_diff_2(partly_new[i], partly_old[i])\n",
    "            for el in difference['added']:\n",
    "                fully_added.append(el)\n",
    "            for el in difference['deleted']:\n",
    "                fully_removed.append(el)\n",
    "\n",
    "        fully_removed = flatten(fully_removed)\n",
    "        fully_added = flatten(fully_added)\n",
    "        while '' in fully_added:\n",
    "            fully_added.remove('')\n",
    "        while '+' in fully_added:\n",
    "            fully_added.remove('+')\n",
    "        while '-' in fully_added:\n",
    "            fully_added.remove('-')\n",
    "\n",
    "        while '' in fully_removed:\n",
    "            fully_removed.remove('')\n",
    "        while '+' in fully_removed:\n",
    "            fully_removed.remove('+')\n",
    "        while '-' in fully_removed:\n",
    "            fully_removed.remove('-')\n",
    "\n",
    "        # Original output_lib was a dictionary\n",
    "        #output_lib = {'added': fully_added, 'removed': fully_removed}\n",
    "\n",
    "        output_str = ''\n",
    "        # However, now we'd like to have the output in a list with seperator \"|SEPERATIONLINEADDEDREMOVED|\"\n",
    "        for word in fully_added:\n",
    "            output_str += '{} '.format(word)\n",
    "\n",
    "        output_str += ' |SEPERATIONLINEADDEDREMOVED|'\n",
    "\n",
    "        for word in fully_removed:\n",
    "            output_str += ' {}'.format(word)\n",
    "\n",
    "        full_difference = []\n",
    "\n",
    "        return output_str\n",
    "    except:\n",
    "        return 'error_would_occur'\n",
    "\n",
    "def find_similar_chunks(chunk_list):\n",
    "    \n",
    "    \"\"\" takes in the differences between two blocks of\n",
    "    text and returns the exact deletion and added chunks\n",
    "    Not important to understand this function, it was a means \n",
    "    to process the output from get_diff_1 in order to process \n",
    "    further, it speeds up the process\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fully_added, fully_removed, partly_removed, partly_added = [], [], [], []\n",
    "    # Remove '', ---, +++\n",
    "    while '' in chunk_list:\n",
    "        chunk_list.remove('')\n",
    "    while '+++ ' in chunk_list:\n",
    "        chunk_list.remove('+++ ')\n",
    "    while '--- ' in chunk_list:\n",
    "        chunk_list.remove('--- ')\n",
    "    for chunk in chunk_list:\n",
    "        try:\n",
    "            if chunk[3] not in string.ascii_letters + '\\'-+ 1234567890':\n",
    "                chunk_list.remove(chunk)\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            chunk_list.remove(chunk)\n",
    "\n",
    "    for a, b in itertools.combinations(chunk_list, 2):\n",
    "        if a[1:30] == b[1:30]:\n",
    "            if a[0] == '+':\n",
    "                partly_added.append(a)\n",
    "                partly_removed.append(b)\n",
    "                chunk_list.remove(a)\n",
    "                chunk_list.remove(b)\n",
    "            else:\n",
    "                partly_added.append(b)\n",
    "                partly_removed.append(a)\n",
    "                chunk_list.remove(a)\n",
    "                chunk_list.remove(b)\n",
    "    for rest in chunk_list:\n",
    "        if rest[0] == '-':\n",
    "            fully_removed.append(rest[1:].split(' '))\n",
    "        elif rest[0] == '+':\n",
    "            fully_added.append(rest[1:].split(' '))\n",
    "    return fully_added, fully_removed, partly_removed, partly_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clean columns: *comments, title, user, text_old, text_new*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanhtml(raw_html):\n",
    "    \n",
    "    \"\"\"\n",
    "    Clean a raw text part from html symbols and words\n",
    "    \"\"\"\n",
    "    \n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    \n",
    "    # Remove urls\n",
    "    cleantext_no_urls = re.sub(r\"http\\S+\", \"\", cleantext)\n",
    "    return cleantext_no_urls\n",
    "\n",
    "def cleantext(raw):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans a raw text part further from other unimportant characters and make it lower case\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # If there's nothing in raw, return 'EMPTY'\n",
    "    for item in 'azertyuiopmlkjhgfdsqnbvcxw,;:=ùµ$^)àç!è§(é&1234567890\\\"\\')|@#]}{[^-_':\n",
    "        if item in raw:\n",
    "    \n",
    "            cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "            cleantext = re.sub(cleanr, '', raw)\n",
    "\n",
    "            # Remove urls\n",
    "            cleantext_no_urls = re.sub(r\"http\\S+\", \"\", cleantext)\n",
    "            return ''.join([x for x in cleantext_no_urls if x in string.ascii_letters + '\\'-+ 1234567890']).lower()\n",
    "    return 'empty'\n",
    "\n",
    "def get_clean_df(df):\n",
    "    \n",
    "    \"\"\" used to pass the dataframe and clean its columns \n",
    "    \"\"\"\n",
    "\n",
    "    # Remove url_page column\n",
    "    df_without_url = df.drop('url_page')\n",
    "\n",
    "    # Cleaning comment, title_page and name_user\n",
    "    clean_udf = udf(cleantext, StringType())\n",
    "    df_without_url = df_without_url.withColumn('clean_comment', clean_udf(df_without_url.comment)).drop('comment')\n",
    "    df_without_url = df_without_url.withColumn('clean_title_page', clean_udf(df_without_url.title_page)).drop('title_page')\n",
    "    df_without_url = df_without_url.withColumn('clean_name_user', clean_udf(df_without_url.name_user)).drop('name_user')\n",
    "    \n",
    "    # Clean the old and new text columns\n",
    "    df_without_url = df_without_url.withColumn('clean_old_text', clean_udf(df_without_url.text_old))\n",
    "    df_without_url = df_without_url.withColumn('clean_new_text', clean_udf(df_without_url.text_new))\n",
    "    \n",
    "    data = df_without_url.select(col(\"label\"), col(\"clean_comment\").alias(\"comment\"), col(\"clean_title_page\").alias(\"title_page\"), col(\"clean_name_user\").alias(\"name_user\"), col(\"text_old\"), col(\"text_new\"), col(\"clean_old_text\"), col(\"clean_new_text\"))\n",
    "    return data\n",
    "\n",
    "def get_difference_column(df):\n",
    "    \n",
    "    \"\"\" takes in the dataframe and returns a dataframe with an extra 'difference' column drops the text_old and text_new columns\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    difference_udf = udf(extract_differences, StringType())\n",
    "    intermediate_col = df.withColumn('difference', difference_udf(df.text_old, df.text_new))\n",
    "    intermediate_col = intermediate_col.drop('text_old')\n",
    "    intermediate_col = intermediate_col.drop('text_new')\n",
    "    return intermediate_col\n",
    "\n",
    "def paste_words(list_of_words):\n",
    "    \n",
    "    \"\"\" pastes together a list of words\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    return ' '.join([x for x in list_of_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Split *difference column* into added and removed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_removed_col(col):\n",
    "    \n",
    "    \"\"\" splits the 'difference' column and returns the removed words\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in 'azertyuiopmlkjhgfdsqnbvcxw,;:=ùµ$^)àç!è§(é&1234567890\\\"\\')|@#]}{[^-_':\n",
    "            if item in col[:col.find('|SEPERATIONLINEADDEDREMOVED|')]:\n",
    "                return col[:col.find('|SEPERATIONLINEADDEDREMOVED|')].split(' ')\n",
    "    return ['empty']\n",
    "\n",
    "def get_added_col(col):\n",
    "    \n",
    "    \"\"\" splits the 'difference' column and returns the added words\n",
    "    \"\"\"\n",
    "\n",
    "    for item in 'azertyuiopmlkjhgfdsqnbvcxw,;:=ùµ$^)àç!è§(é&1234567890\\\"\\')|@#]}{[^-_':\n",
    "            if item in col[col.find('|SEPERATIONLINEADDEDREMOVED|') + len('|SEPERATIONLINEADDEDREMOVED|') + 1:]:\n",
    "                return col[col.find('|SEPERATIONLINEADDEDREMOVED|') + len('|SEPERATIONLINEADDEDREMOVED|') + 1:].split(' ')\n",
    "    return ['empty']\n",
    "\n",
    "\n",
    "def split_difference_into_removed_added(df):\n",
    "    \n",
    "    \"\"\"splits the difference column and adds two new columns: added_words and removed_words\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    get_removed_udf = udf(get_removed_col, types.ArrayType(types.StringType()).simpleString())\n",
    "    df = df.withColumn('removed_words', get_removed_udf(df.difference))\n",
    "    \n",
    "    get_added_udf = udf(get_added_col, types.ArrayType(types.StringType()).simpleString())\n",
    "    df = df.withColumn('added_words', get_added_udf(df.difference))\n",
    "    \n",
    "    df = df.drop('difference')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and look at class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the data as spark dataframe\n",
    "# wiki_df = get_wiki_df(path=\"../data/subset/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label distribution when using all data: \n",
    "  - safe: 30333\n",
    "  - unsafe: 4136\n",
    "  - vandal: 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class_dist = get_label_count(wiki_df)\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# ax = class_dist.select(\"*\").toPandas().plot.bar(x='label', y='count(1)', rot=0, legend=False)\n",
    "# ax.set_xlabel(\"Classes\")\n",
    "# ax.set_ylabel(\"Count\")\n",
    "\n",
    "# # save figure\n",
    "# plt.savefig('../output/figures/fig1.png', dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| label|             comment|          title_page|           name_user|      clean_old_text|      clean_new_text|          difference|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  safe|            map date|201920 coronaviru...|       raphal dunant|redirectcoronavir...|redirectcoronavir...|4  |SEPERATIONLIN...|\n",
      "|  safe|       typo viawpjwb|yemeni civil war ...|        alistair1978|other usesyemen w...|other usesyemen w...|since the mid-200...|\n",
      "|unsafe|               empty|                2019|         annettespry|pp-protectedsmall...|pp-protectedsmall...|cameron boyce ame...|\n",
      "|  safe|2327 marchbroke p...|2020 stock market...|commonknowledgecr...|pp-vandalismsmall...|pp-vandalismsmall...|the bank of japan...|\n",
      "|  safe|               empty|united states men...|              phikia|filetschroederjpg...|filetschroederjpg...|goalkeepers with ...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Get clean dataframe (cleaning of comment, title_page, name_user):\n",
    "# clean_df = get_clean_df(wiki_df)\n",
    "\n",
    "# #In order to get the actual difference column\n",
    "# df_with_difference = get_difference_column(clean_df)\n",
    "\n",
    "# #Example of a difference column of the first of 20 instances:\n",
    "# # difference column is in the form REMOVED PART |SEPERATIONLINEADDEDREMOVED| ADDED PART\n",
    "# df_with_difference.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| label|             comment|          title_page|           name_user|      clean_old_text|      clean_new_text|       removed_words|         added_words|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  safe|            map date|201920 coronaviru...|       raphal dunant|redirectcoronavir...|redirectcoronavir...|             [4, , ]|                [33]|\n",
      "|  safe|       typo viawpjwb|yemeni civil war ...|        alistair1978|other usesyemen w...|other usesyemen w...|[since, the, mid-...|[since, the, mid-...|\n",
      "|unsafe|               empty|                2019|         annettespry|pp-protectedsmall...|pp-protectedsmall...|[cameron, boyce, ...|             [empty]|\n",
      "|  safe|2327 marchbroke p...|2020 stock market...|commonknowledgecr...|pp-vandalismsmall...|pp-vandalismsmall...|[the, bank, of, j...|[, the, bank, of,...|\n",
      "|  safe|               empty|united states men...|              phikia|filetschroederjpg...|filetschroederjpg...|[goalkeepers, wit...|[goalkeepers, wit...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 2 columns: removed and added with space in new function. + Clean text_old and text_new\n",
    "# # Split difference column into column 'removed' and column 'added'\n",
    "\n",
    "# final_df = split_difference_into_removed_added(df_with_difference)\n",
    "# final_df.show(5)\n",
    "# final_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Save final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check if input and output is the same before and after saving\n",
    "# final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save\n",
    "# final_df.write.mode(\"overwrite\").save(\"../output/output_preprocessing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in data\n",
    "# final_df = spark.read.parquet(\"../output/output_preprocessing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check if input and output is the same before and after saving\n",
    "# final_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Needed for final pipeline\n",
    "\n",
    "Below you can find a summary of code needed for the data cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note this is a markdown cell\n",
    "```python\n",
    "\n",
    "# Get the data as spark dataframe\n",
    "wiki_df = get_wiki_df(path=\"../data/subset/*\")\n",
    "\n",
    "#Get clean dataframe (cleaning of comment, title_page, name_user):\n",
    "clean_df = get_clean_df(wiki_df)\n",
    "\n",
    "#In order to get the actual difference column\n",
    "df_with_difference = get_difference_column(clean_df)\n",
    "\n",
    "# 2 columns: removed and added with space in new function. + Clean text_old and text_new\n",
    "# Split difference column into column 'removed' and column 'added'\n",
    "final_df = split_difference_into_removed_added(df_with_difference)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
