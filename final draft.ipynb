{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and transfer into dataframe\n",
    "import os\n",
    "rootdir = 'C:/material/Courses/stage 2/big data/assignment 3/data 2'\n",
    "\n",
    "files_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for name in files:\n",
    "        if \"part\" in name.lower() and not \".crc\" in name.lower():\n",
    "            files_list.append(os.path.join(subdir,name))\n",
    "df = spark.read.json(sc.textFile(','.join(files_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| label|count|\n",
      "+------+-----+\n",
      "|  safe|   18|\n",
      "|vandal|   12|\n",
      "|unsafe|    6|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# frequency table\n",
    "from pyspark.sql.functions import col\n",
    "df.groupBy('label').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import unified_diff\n",
    "\n",
    "def make_diff(old, new):\n",
    "    return '\\n'.join([ l for l in unified_diff(old.split('\\n'), new.split('\\n')) if l.startswith('+') or l.startswith('-') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making a diff between text_old and text_new\n",
    "diff = make_diff(df.first().text_old, df.first().text_new)\n",
    "df = df.withColumn(\"diff\", lit(diff))\n",
    "\n",
    "# drop useless features\n",
    "drop_list = ['comment', 'name_user', 'title_page', 'url_page',\"text_old\", \"text_new\"]\n",
    "df = df.select([column for column in df.columns if column not in drop_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#replace empty string  with 'null' \n",
    "from pyspark.sql.functions import col, when\n",
    "df = df.withColumn(\"diff\", when(col('diff') != ' ', col('diff')).otherwise(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values\n",
    "df = df.na.drop(subset = 'diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "##################  count vector features ##########################\n",
    "####################################################################\n",
    "\n",
    "###### preprocessing pipeline ##############\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Data Count:26\n",
      "test data count:10\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test data\n",
    "(train, test) = df.randomSplit([0.8,0.2], seed = 775346)\n",
    "print('train Data Count:' + str(train.count()))\n",
    "print('test data count:' + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature transformer: \n",
    "# tokenizer (split sentences into words)\n",
    "regexTokenizer = RegexTokenizer(inputCol = 'diff', outputCol = 'words', pattern = '\\\\W')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fanqi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove the stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwordList = nltk.corpus.stopwords.words('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords = stopwordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count bag of words\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=20000, minDF=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding dependent feature 'label'\n",
    "label_stringIdx = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
    "labels_stars = label_stringIdx.fit(train).labels\n",
    "indexed = label_stringIdx.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the pipeline to train and test data seperately\n",
    "pipelineFit = pipeline.fit(train)\n",
    "train_pipe = pipelineFit.transform(train)\n",
    "#train_pipe.show()\n",
    "test_pipe = pipelineFit.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### off-line model training #######################\n",
    "########### logistic regression by using count vector features #####\n",
    "####################################################################\n",
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model \n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "lrModel = lr.fit(train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test_pipe data\n",
    "predictions = lrModel.transform(test_pipe)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.filter(predictions['prediction'] == 0)\\\n",
    "# #          .select('text_new','probability','label','predictedLabel')\\\n",
    " ##          .orderBy('probability', ascending = False)\\\n",
    " #          .show(n=20, truncate = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for multiple classification evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "evaluator.evaluate(predictions) # accuracy\n",
    "\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "evaluator_F1.evaluate(predictions) # F1 score       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossvalidation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pipe)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test_pipe data\n",
    "predictions = cvModel.transform(test_pipe)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7217675941080196\n",
      "Test set F1 score = 0.7217675941080196\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction'，metricName='accuracy')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.filter(predictions['prediction'] == 0)\\\n",
    "#          .select('text_new','probability','label','predictedLabel')\\\n",
    "#           .orderBy('probability', ascending = False)\\\n",
    "#           .show(n=20, truncate = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########### Naive Bayes by using count vector features #############\n",
    "####################################################################\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1, modelType=\"multinomial\", featuresCol = 'features', labelCol = 'labelIndex' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with train_pipe data \n",
    "model = nb.fit(train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------+--------------+\n",
      "|                      text_new|                   probability| label|predictedLabel|\n",
      "+------------------------------+------------------------------+------+--------------+\n",
      "|{{Use dmy dates|date=April ...|[1.0,6.972695125448627E-19,...|  safe|          safe|\n",
      "|{{For|the federal election|...|[1.0,9.191506784201759E-113...|  safe|          safe|\n",
      "|{{short description|Wikiped...|[0.9999990001846086,9.99815...|vandal|          safe|\n",
      "|{{notability|1=Biographies|...|[0.9999954372568007,1.19131...|  safe|          safe|\n",
      "|\n",
      "\n",
      "{{short description||bot=...|[0.987731771298586,5.169991...|  safe|          safe|\n",
      "|{{Infobox software\n",
      "| name  ...|[0.8938136428475434,0.01979...|  safe|          safe|\n",
      "|{{redirect|Patrick Lumumba|...|[0.5419811683574965,5.46365...|  safe|          safe|\n",
      "|{{short description|GRID is...|[0.5293616161103452,2.42185...|  safe|          safe|\n",
      "|'''Tswana''' may refer to:\n",
      "...|[0.5149007383910856,0.25196...|vandal|          safe|\n",
      "+------------------------------+------------------------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = model.transform(test_pipe)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "# take a while to run this code, run it only if needed\n",
    "# predictions.filter(predictions['prediction'] == 0)\\\n",
    "#           .select('text_new','probability','label','predictedLabel')\\\n",
    "#           .orderBy(\"probability\", ascending=False)\\\n",
    "#          .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.34615384615384615\n",
      "Test set F1 score = 0.41698717948717945\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_BYF1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_BYF1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########### Random Forrest by using count vector features ##########\n",
    "####################################################################\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"labelIndex\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Train_pipe Data\n",
    "rfModel = rf.fit(train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 500]) \n",
    "             .addGrid(rf.maxDepth, [4, 10, 20])\n",
    "             .build())\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_validation train\n",
    "cvmodel = cv.fit(train_pipe)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7217675941080196\n",
      "Test set F1 score = 0.7217675941080196\n"
     ]
    }
   ],
   "source": [
    "# predict with test_pipe data\n",
    "predictions = cvModel.transform(test_pipe)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### TF—IDF Features  ############################\n",
    "####################################################################\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq = 5)\n",
    "\n",
    "pipeline_tfidf = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF , idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appply pipeline to train and test data\n",
    "pipelineFit_tfidf = pipeline_tfidf.fit(train)\n",
    "train_pipe_tfidf = pipelineFit_tfidf.transform(train)\n",
    "\n",
    "test_pipe_tfidf = pipelineFit_tfidf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|                                     text_new|                                  probability| label|predictedLabel|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|[[File:Merton London UK labelled ward map ...|[1.0,2.949127344484627E-21,3.0564044018527...|  safe|          safe|\n",
      "|{{For|the federal election|2020 United Sta...|[1.0,4.0061517241228436E-63,1.046061002925...|  safe|          safe|\n",
      "|{{short description|Wikipedia list article...|[0.9999999999999998,9.677946128900213E-18,...|vandal|          safe|\n",
      "|Cole sprouse, was born 2007-2020\n",
      "Cole went...|[0.9999999988016179,1.1593483902299663E-9,...|vandal|          safe|\n",
      "|{{Use dmy dates|date=April 2020}}\n",
      "The [[Au...|[0.9999999966944775,1.0558498232836677E-11...|  safe|          safe|\n",
      "|{{Infobox song\n",
      "| name       = Dirt on My B...|[0.9998412206078008,2.8965858715395515E-5,...|  safe|          safe|\n",
      "|{{short description|GRID is a productivity...|[0.9982903814613843,4.873900405035705E-4,0...|  safe|          safe|\n",
      "|{{notability|1=Biographies|date=March 2020...|[0.9854017134897636,0.0034527215270204266,...|  safe|          safe|\n",
      "|{{Expand Vietnamese|Lấp Vò|date=March 2009...|[0.981778060145278,0.016479135261675815,0....|  safe|          safe|\n",
      "|{{Use Pakistani English|date=June 2015}}\n",
      "{...|[0.9622093954432295,1.1607161138331818E-5,...|unsafe|          safe|\n",
      "|{{Infobox software\n",
      "| name                 ...|[0.9384010562798469,0.0465220064479721,0.0...|  safe|          safe|\n",
      "|{{Use Australian English|date=May 2019}}\n",
      "{...|[0.9326770816002272,0.06578952444079189,0....|  safe|          safe|\n",
      "|{{short description|French footballer}}\n",
      "{{...|[0.9209335743325763,0.053523654187538156,0...|  safe|          safe|\n",
      "|{{Use dmy dates|date=September 2019}}\n",
      "{{Us...|[0.919492079057411,0.07616165611605968,0.0...|  safe|          safe|\n",
      "|\n",
      "\n",
      "{{short description||bot=}}\n",
      "{{Infobox sc...|[0.9086319821359925,0.02849670261881615,0....|  safe|          safe|\n",
      "|{{more citations needed|date=September 201...|[0.8865993978735162,0.03979772192954223,0....|  safe|          safe|\n",
      "|{{short description|Wikimedia list article...|[0.8345348366347448,6.0297485658618995E-5,...|  safe|          safe|\n",
      "|{{Use dmy dates|date=May 2016}}\n",
      "{{Use Brit...|[0.7532481396306034,0.20392334841367382,0....|unsafe|          safe|\n",
      "|{{Infobox automobile\n",
      "| name = UMM Alter 4x...|[0.7032034711869807,0.152243496645159,0.14...|  safe|          safe|\n",
      "|'''Tswana''' may refer to:\n",
      "* [[Tswana (eth...|[0.6425151600513226,0.17172016013177,0.185...|vandal|          safe|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################### off-line model training #######################\n",
    "########### logistic regression by using TF_IDF features ###########\n",
    "####################################################################\n",
    "\n",
    "# fit a model \n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "lrModel = lr.fit(train_pipe_tfidf)\n",
    "\n",
    "# predict with test data\n",
    "predictions = lrModel.transform(test_pipe_tfidf)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "#predictions.filter(predictions['prediction'] == 0)\\\n",
    "#           .select('text_new','probability','label','predictedLabel')\\\n",
    "#           .orderBy('probability', ascending = False)\\\n",
    "#           .show(n=20, truncate = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple classification evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "evaluator.evaluate(predictions) # accuracy\n",
    "\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "evaluator_F1.evaluate(predictions) # F1 score \n",
    "\n",
    "# crossvalidation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)\n",
    "# cvModel = cv.fit(train_pipe_tfidf)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pipe_tfidf)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test data\n",
    "predictions = cvModel.transform(test_pipe_tfidf)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.6820512820512821\n",
      "Test set F1 score = 0.6820512820512821\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|                                     text_new|                                  probability| label|predictedLabel|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|{{For|the federal election|2020 United Sta...|[1.0,6.611809568529717E-19,2.0697655966562...|  safe|          safe|\n",
      "|[[File:Merton London UK labelled ward map ...|[0.9999999147509985,3.6806845261450523E-8,...|  safe|          safe|\n",
      "|{{Use dmy dates|date=April 2020}}\n",
      "The [[Au...|[0.9928664912641214,0.002933667246850246,0...|  safe|          safe|\n",
      "|{{short description|Wikipedia list article...|[0.9897320934267761,0.010231605693713394,3...|vandal|          safe|\n",
      "|Cole sprouse, was born 2007-2020\n",
      "Cole went...|[0.9875916052387613,0.010001452968845116,0...|vandal|          safe|\n",
      "|{{Infobox song\n",
      "| name       = Dirt on My B...|[0.9494401707247841,0.024509264537738794,0...|  safe|          safe|\n",
      "|{{short description|GRID is a productivity...|[0.9029413196440209,0.047391207557841035,0...|  safe|          safe|\n",
      "|{{Expand Vietnamese|Lấp Vò|date=March 2009...|[0.7940678446262944,0.14271884357877726,0....|  safe|          safe|\n",
      "|{{notability|1=Biographies|date=March 2020...|[0.760542436424001,0.10817801298512389,0.1...|  safe|          safe|\n",
      "|{{short description|Wikimedia list article...|[0.7386989315995461,0.1254496392329597,0.1...|  safe|          safe|\n",
      "|{{Infobox software\n",
      "| name                 ...|[0.7319412565548601,0.1690099526830481,0.0...|  safe|          safe|\n",
      "|{{short description|French footballer}}\n",
      "{{...|[0.7091266185187384,0.18309458119464586,0....|  safe|          safe|\n",
      "|\n",
      "\n",
      "{{short description||bot=}}\n",
      "{{Infobox sc...|[0.7015932656560286,0.1520344209178776,0.1...|  safe|          safe|\n",
      "|{{Use dmy dates|date=May 2016}}\n",
      "{{Use Brit...|[0.6469055582060175,0.2290730303570494,0.1...|unsafe|          safe|\n",
      "|{{Use Pakistani English|date=June 2015}}\n",
      "{...|[0.6315097270211195,0.05089830346335326,0....|unsafe|          safe|\n",
      "|{{Infobox automobile\n",
      "| name = UMM Alter 4x...|[0.6246734750997807,0.20502717219233654,0....|  safe|          safe|\n",
      "|{{Use dmy dates|date=September 2019}}\n",
      "{{Us...|[0.622470675643768,0.30460205634710147,0.0...|  safe|          safe|\n",
      "|{{more citations needed|date=September 201...|[0.6221855208448969,0.20377356931635177,0....|  safe|          safe|\n",
      "|{{Infobox book \n",
      "  | name           =  Coll...|[0.6202118988455283,0.22216715692462663,0....|  safe|          safe|\n",
      "|'''Tswana''' may refer to:\n",
      "* [[Tswana (eth...|[0.6060168214750076,0.2139794735975505,0.1...|vandal|          safe|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))\n",
    "\n",
    "#predictions.filter(predictions['prediction'] == 0)\\\n",
    "#           .select('text_new','probability','label','predictedLabel')\\\n",
    "#           .orderBy('probability', ascending = False)\\\n",
    "#          .show(n=20, truncate = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------+--------------+\n",
      "|                      text_new|                   probability| label|predictedLabel|\n",
      "+------------------------------+------------------------------+------+--------------+\n",
      "|{{Use dmy dates|date=May 20...|[1.0,1.7243874070756806E-30...|unsafe|          safe|\n",
      "|{{Expand Vietnamese|Lấp Vò|...|[1.0,2.3215327594100197E-40...|  safe|          safe|\n",
      "|{{more citations needed|dat...|[1.0,4.763501085087394E-49,...|  safe|          safe|\n",
      "|{{Infobox software\n",
      "| name  ...|[1.0,7.83105209213923E-98,9...|  safe|          safe|\n",
      "|{{Use dmy dates|date=Septem...|[1.0,4.7421126313870003E-13...|  safe|          safe|\n",
      "|{{short description|GRID is...|[1.0,3.249697534681906E-163...|  safe|          safe|\n",
      "|{{notability|1=Biographies|...|[1.0,1.2317670434709667E-21...|  safe|          safe|\n",
      "|{{Use Australian English|da...|[1.0,1.13340600465693E-222,...|  safe|          safe|\n",
      "|'''Atom transfer radical po...|[1.0,1.3134417208456763E-23...|  safe|          safe|\n",
      "|{{Drugbox\n",
      "| Verifiedfields ...|[1.0,3.0483010708584216E-23...|  safe|          safe|\n",
      "+------------------------------+------------------------------+------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "########### Naive Bayes by using TF-IDF features #############\n",
    "####################################################################\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1, modelType=\"multinomial\", featuresCol = 'features', labelCol = 'labelIndex' )\n",
    "\n",
    "# train model with train data \n",
    "model = nb.fit(train_pipe_tfidf)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.transform(test_pipe_tfidf)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0)\\\n",
    "           .select('text_new','probability','label','predictedLabel')\\\n",
    "           .orderBy(\"probability\", ascending=False)\\\n",
    "           .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.6153846153846154\n",
      "Test set F1 score = 0.6303939962476548\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_BYF1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_BYF1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########### Random Forrest by using DF-IDF features ################\n",
    "####################################################################\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"labelIndex\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Train Data\n",
    "rfModel = rf.fit(train_pipe_tfidf)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 500]) \n",
    "             .addGrid(rf.maxDepth, [4, 10, 20])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_validation train\n",
    "cvmodel = cv.fit(train_pipe_tfidf)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test data\n",
    "predictions = cvModel.transform(test_pipe_tfidf)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.6820512820512821\n",
      "Test set F1 score = 0.6820512820512821\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### Word2Vec Features  ##########################\n",
    "####################################################################\n",
    "\n",
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2Vec\n",
    "w2v = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "\n",
    "pipeline_w2v = Pipeline(stages=[regexTokenizer, stopwordsRemover, w2v, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appply pipeline to train and test data\n",
    "pipelineFit_w2v = pipeline_w2v.fit(train)\n",
    "train_pipe_w2v = pipelineFit_w2v.transform(train)\n",
    "\n",
    "test_pipe_w2v = pipelineFit_w2v.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|                                     text_new|                                  probability| label|predictedLabel|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|{{Use dmy dates|date=April 2020}}\n",
      "The [[Au...|[0.9606433524623734,0.03922165361234626,1....|  safe|          safe|\n",
      "|{{Use dmy dates|date=May 2016}}\n",
      "{{Use Brit...|[0.743546245253475,0.20646003457521092,0.0...|unsafe|          safe|\n",
      "|[[File:Merton London UK labelled ward map ...|[0.7127614380612451,0.18800563205504853,0....|  safe|          safe|\n",
      "|{{Infobox book \n",
      "  | name           =  Coll...|[0.7006490816116543,0.22582590247146758,0....|  safe|          safe|\n",
      "|{{Drugbox\n",
      "| Verifiedfields = changed\n",
      "| Wat...|[0.6838535250703675,0.22862336277769776,0....|  safe|          safe|\n",
      "|{{For|the federal election|2020 United Sta...|[0.6770435561599338,0.19372361544594263,0....|  safe|          safe|\n",
      "|{{more citations needed|date=September 201...|[0.6659924160797496,0.2081934423983161,0.1...|  safe|          safe|\n",
      "|{{short description|French footballer}}\n",
      "{{...|[0.6546906983439135,0.21692647629678113,0....|  safe|          safe|\n",
      "|{{Infobox software\n",
      "| name                 ...|[0.6474884729319043,0.22401263227048793,0....|  safe|          safe|\n",
      "|{{Use Pakistani English|date=June 2015}}\n",
      "{...|[0.6460567654301118,0.23072059497706934,0....|unsafe|          safe|\n",
      "|{{redirect|Patrick Lumumba|the Congolese i...|[0.6340094126080043,0.2073055282378216,0.1...|  safe|          safe|\n",
      "|\n",
      "\n",
      "{{short description||bot=}}\n",
      "{{Infobox sc...|[0.6279707935093151,0.2172648614909072,0.1...|  safe|          safe|\n",
      "|{{Use dmy dates|date=September 2019}}\n",
      "{{Us...|[0.6278284212677487,0.218657225524131,0.15...|  safe|          safe|\n",
      "|'''Atom transfer radical polymerization'''...|[0.6238636817191983,0.25650600250784417,0....|  safe|          safe|\n",
      "|{{notability|1=Biographies|date=March 2020...|[0.6198223952607398,0.21595760123646543,0....|  safe|          safe|\n",
      "|{{Expand Vietnamese|Lấp Vò|date=March 2009...|[0.6022895396290537,0.2687732753252869,0.1...|  safe|          safe|\n",
      "|{{Use Australian English|date=May 2019}}\n",
      "{...|[0.6021046868568302,0.20867686475239647,0....|  safe|          safe|\n",
      "|Cole sprouse, was born 2007-2020\n",
      "Cole went...|[0.5899491341701133,0.21561989835194972,0....|vandal|          safe|\n",
      "|{{short description|Wikipedia list article...|[0.5898171394611332,0.26516230197473617,0....|vandal|          safe|\n",
      "|{{Use dmy dates|date=November 2019}}\n",
      "{{Use...|[0.5611148787524909,0.23874743140136534,0....|  safe|          safe|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################### off-line model training #######################\n",
    "########### logistic regression by using Word2Vec features #########\n",
    "####################################################################\n",
    "\n",
    "# fit a model \n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "lrModel = lr.fit(train_pipe_w2v)\n",
    "\n",
    "# predict with test data\n",
    "predictions = lrModel.transform(test_pipe_w2v)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0)\\\n",
    "           .select('text_new','probability','label','predictedLabel')\\\n",
    "           .orderBy('probability', ascending = False)\\\n",
    "           .show(n=20, truncate = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple classification evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "evaluator.evaluate(predictions) # accuracy\n",
    "\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "evaluator_F1.evaluate(predictions) # F1 score \n",
    "\n",
    "# crossvalidation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labelIndex', maxIter = 10, regParam = 0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_pipe_w2v)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7217675941080196\n",
      "Test set F1 score = 0.7217675941080196\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|                                     text_new|                                  probability| label|predictedLabel|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "|{{Use dmy dates|date=April 2020}}\n",
      "The [[Au...|[0.6479369580226959,0.1920083302837148,0.1...|  safe|          safe|\n",
      "|{{short description|GRID is a productivity...|[0.6093483555596151,0.20658114203790565,0....|  safe|          safe|\n",
      "|[[File:Merton London UK labelled ward map ...|[0.6055444277226629,0.21408550431700488,0....|  safe|          safe|\n",
      "|{{For|the federal election|2020 United Sta...|[0.6035922367205283,0.21551591107325252,0....|  safe|          safe|\n",
      "|{{Use dmy dates|date=May 2016}}\n",
      "{{Use Brit...|[0.6014709814163648,0.2196349664987885,0.1...|unsafe|          safe|\n",
      "|{{Infobox song\n",
      "| name       = Dirt on My B...|[0.6012349328422597,0.21348839446071036,0....|  safe|          safe|\n",
      "|{{more citations needed|date=September 201...|[0.6005853975388918,0.2178746477770833,0.1...|  safe|          safe|\n",
      "|{{redirect|Patrick Lumumba|the Congolese i...|[0.5999885298908054,0.21734940993911586,0....|  safe|          safe|\n",
      "|{{short description|French footballer}}\n",
      "{{...|[0.598746537556594,0.2191672654997367,0.18...|  safe|          safe|\n",
      "|{{Use Australian English|date=May 2019}}\n",
      "{...|[0.598723107856356,0.21771114640758582,0.1...|  safe|          safe|\n",
      "|\n",
      "\n",
      "{{short description||bot=}}\n",
      "{{Infobox sc...|[0.5980613991700282,0.21878780722794786,0....|  safe|          safe|\n",
      "|{{notability|1=Biographies|date=March 2020...|[0.5980243752667288,0.21871095737347399,0....|  safe|          safe|\n",
      "|{{Infobox book \n",
      "  | name           =  Coll...|[0.5976696826223302,0.22197758706124632,0....|  safe|          safe|\n",
      "|{{Use dmy dates|date=September 2019}}\n",
      "{{Us...|[0.5975362653623534,0.22035194299254102,0....|  safe|          safe|\n",
      "|{{Infobox software\n",
      "| name                 ...|[0.5973261138284386,0.2202329489656553,0.1...|  safe|          safe|\n",
      "|{{Drugbox\n",
      "| Verifiedfields = changed\n",
      "| Wat...|[0.5970641406174323,0.22186314863607734,0....|  safe|          safe|\n",
      "|Cole sprouse, was born 2007-2020\n",
      "Cole went...|[0.5969023704021392,0.21972645490962595,0....|vandal|          safe|\n",
      "|{{Use Pakistani English|date=June 2015}}\n",
      "{...|[0.5960177903569035,0.22180931912366192,0....|unsafe|          safe|\n",
      "|{{Infobox automobile\n",
      "| name = UMM Alter 4x...|[0.5955708129094764,0.22075643863059016,0....|  safe|          safe|\n",
      "|'''Tswana''' may refer to:\n",
      "* [[Tswana (eth...|[0.5937100890951459,0.22055101249134731,0....|vandal|          safe|\n",
      "+---------------------------------------------+---------------------------------------------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with test data\n",
    "predictions = cvModel.transform(test_pipe_w2v)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0)\\\n",
    "           .select('text_new','probability','label','predictedLabel')\\\n",
    "           .orderBy('probability', ascending = False)\\\n",
    "           .show(n=20, truncate = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o35268.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 4741.0 failed 1 times, most recent failure: Lost task 6.0 in stage 4741.0 (TID 344694, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.12187534458413023,-0.2043117031223297,-0.1748945412729762].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$apply$6.apply(PairRDDFunctions.scala:172)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:144)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.12187534458413023,-0.2043117031223297,-0.1748945412729762].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$apply$6.apply(PairRDDFunctions.scala:172)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:144)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-47515b87fc9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# train model with train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pipe_w2v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o35268.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 4741.0 failed 1 times, most recent failure: Lost task 6.0 in stage 4741.0 (TID 344694, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.12187534458413023,-0.2043117031223297,-0.1748945412729762].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$apply$6.apply(PairRDDFunctions.scala:172)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:144)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.12187534458413023,-0.2043117031223297,-0.1748945412729762].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$apply$6.apply(PairRDDFunctions.scala:172)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:144)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "########### Naive Bayes by using Word2Vec features #############\n",
    "####################################################################\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1, modelType=\"multinomial\", featuresCol = 'features', labelCol = 'labelIndex' )\n",
    "\n",
    "# train model with train data \n",
    "model = nb.fit(train_pipe_w2v)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.transform(test_pipe_w2v)\n",
    "predictions = labelConverter.transform(predictions)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0)\\\n",
    "           .select('text_new','probability','label','predictedLabel')\\\n",
    "           .orderBy(\"probability\", ascending=False)\\\n",
    "           .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_BYF1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_BYF1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "########### Random Forrest by using Word2Vec features ##############\n",
    "####################################################################\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"labelIndex\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Train Data\n",
    "rfModel = rf.fit(train_pipe_w2v)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 500]) \n",
    "             .addGrid(rf.maxDepth, [4, 10, 20])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator, \n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_validation train\n",
    "cvmodel = cv.fit(train_pipe_w2v)  # be careful, takes very long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test data\n",
    "predictions = cvModel.transform(test_pipe_w2v)\n",
    "# transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol = \"prediction\", outputCol = 'PredictedLabel', labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7217675941080196\n",
      "Test set F1 score = 0.7217675941080196\n"
     ]
    }
   ],
   "source": [
    "# evaluate best model---accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol = 'prediction')\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "# F1 score\n",
    "evaluator_F1= MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='labelIndex', metricName='f1')\n",
    "F1 = evaluator_F1.evaluate(predictions)\n",
    "print(\"Test set F1 score = \" + str(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### saving complete pipeline for online prediction #### RF model using W2V\n",
    "\n",
    "pipeline_rf_final = Pipeline(stages = [regexTokenizer, stopwordsRemover, w2v, label_stringIdx, rf, labelConverter])\n",
    "pipeline_rf_export = pipeline_rf_final.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o51797.save.\n: java.io.IOException: Path pipeline_rf1 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\r\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:702)\r\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:179)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-595e98ead0b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# export pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipeline_rf_export\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pipeline_rf1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\ml\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;34m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\ml\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.5-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o51797.save.\n: java.io.IOException: Path pipeline_rf1 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\r\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:702)\r\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:179)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "    # export pipeline\n",
    "    pipeline_rf_export.save('pipeline_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################################################\n",
    "#################### online prediction #############################\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import unified_diff\n",
    "\n",
    "def make_diff(old, new):\n",
    "    return '\\n'.join([ l for l in unified_diff(old.split('\\n'), new.split('\\n')) if l.startswith('+') or l.startswith('-') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "\n",
    "def predict(df):\n",
    "    if any([x in df.diff.lower() for x in ['bad', 'lol', 'joke']]):\n",
    "        return 'vandal'\n",
    "    else:\n",
    "        return 'safe'\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    # Tip: making a diff will probably help a lot as a feature in any model:\n",
    "    #diff = make_diff(df.first().text_old, df.first().text_new)\n",
    "    #df_withdiff = df.withColumn(\"diff\", lit(diff))\n",
    "    #df_withdiff.select('diff').show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # making a diff between text_old and text_new\n",
    "    diff = make_diff(df.first().text_old, df.first().text_new)\n",
    "    df = df.withColumn(\"diff\", lit(diff))\n",
    "    \n",
    "    drop_list = ['comment', 'name_user', 'title_page', 'url_page',\"text_old\", \"text_new\"]\n",
    "    df = df.select([column for column in df.columns if column not in drop_list])\n",
    "\n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = 'pipeline_rf' # Replace '***' with:    [...].load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model: \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment|label|       name_user|            text_new|            text_old|          title_page|            url_page|\n",
      "+--------------------+-----+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|tweak template op...| safe|     Archon 2488|{{pp-semi-indef}}...|{{pp-semi-indef}}...|    Gilgit-Baltistan|//en.wikipedia.or...|\n",
      "|→‎2019–present: S...| safe|TheRedundancy125|{{Use mdy dates|d...|{{Use mdy dates|d...|            Maroon 5|//en.wikipedia.or...|\n",
      "|4 star rating fro...| safe|         Muso805|{{Infobox album\n",
      "|...|{{Infobox album\n",
      "|...|Thelonious in Action|//en.wikipedia.or...|\n",
      "|Fixed a typo foun...| safe|     Ira Leviton|{{YYYY music|1899...|{{YYYY music|1899...|       1899 in music|//en.wikipedia.or...|\n",
      "|Changed unsupport...| safe|       John B123|{{short descripti...|{{short descripti...|Thames Tideway Sc...|//en.wikipedia.or...|\n",
      "+--------------------+-----+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "========= 2020-05-23 15:22:40 =========\n",
      "+--------------------+------+------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment| label|   name_user|            text_new|            text_old|          title_page|            url_page|\n",
      "+--------------------+------+------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                    |unsafe|80.3.189.222|[[File:Josephus A...|[[File:Josephus A...|   Josephus on Jesus|//en.wikipedia.or...|\n",
      "|                    |  safe|        EEJB|{{use dmy dates|d...|{{use dmy dates|d...|Pia Nilsson (golfer)|//en.wikipedia.or...|\n",
      "|→‎Notable people:...|  safe|      ArbieP|{{Use dmy dates|d...|{{Use dmy dates|d...|               Kibæk|//en.wikipedia.or...|\n",
      "+--------------------+------+------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "========= 2020-05-23 15:22:50 =========\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment|label|      name_user|            text_new|            text_old|          title_page|            url_page|\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Fixed a typo foun...| safe|    Ira Leviton|{{short descripti...|{{short descripti...|1892 Yale Bulldog...|//en.wikipedia.or...|\n",
      "|4 star rating fro...| safe|        Muso805|{{Infobox album\n",
      "|...|{{Infobox album\n",
      "|...|Art Blakey's Jazz...|//en.wikipedia.or...|\n",
      "|→‎Demographics:Ti...| safe|Rich Farmbrough|{{Infobox settlem...|{{Infobox settlem...|St. Augustine Bea...|//en.wikipedia.or...|\n",
      "|Tidy census wordi...| safe|Rich Farmbrough|{{short descripti...|{{Distinguish|Ple...|Pleasant Grove, A...|//en.wikipedia.or...|\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "========= 2020-05-23 15:23:00 =========\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment|label|      name_user|            text_new|            text_old|          title_page|            url_page|\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Tidy census wordi...| safe|Rich Farmbrough|{{For|the locatio...|{{For|the locatio...|Vallecito, Califo...|//en.wikipedia.or...|\n",
      "|        →‎References| safe|     Mohsen1248|{{Infobox sports ...|{{Infobox sports ...|Chess at the 2007...|//en.wikipedia.or...|\n",
      "|Tidy census wordi...| safe|Rich Farmbrough|{{Infobox settlem...|{{Infobox settlem...|Mountain Ranch, C...|//en.wikipedia.or...|\n",
      "+--------------------+-----+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
